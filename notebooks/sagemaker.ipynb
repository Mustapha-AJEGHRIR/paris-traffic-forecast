{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal as sg\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import interpn,interp1d,RegularGridInterpolator, Akima1DInterpolator\n",
    "\n",
    "import time\n",
    "from tqdm import notebook\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import tarfile\n",
    "\n",
    "%aimport -sg -mpl -plt -notebook -np -integrate -torch -TensorDataset -DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload,import_module\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_DEFAULT_REGION=eu-west-2\n",
      "/mnt/d/Google Drive/projects/paris-traffic-forecast\n"
     ]
    }
   ],
   "source": [
    "%env AWS_DEFAULT_REGION=eu-west-2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix_in  = 'paris-traffic-forecast/input'\n",
    "prefix_out = 'paris-traffic-forecast/model'\n",
    "role = \"SageMakerRole\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input file (in this case, just an S3 path): s3://sagemaker-eu-west-2-047892910832/paris-traffic-forecast/input\n"
     ]
    }
   ],
   "source": [
    "rep_data = 'tmp'\n",
    "\n",
    "input_channel = sagemaker_session.upload_data(path=rep_data, bucket=bucket, key_prefix=prefix_in)\n",
    "print('input file (in this case, just an S3 path): {}'.format(input_channel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creation des instances et param√©trage de l'estimateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-2-047892910832/paris-traffic-forecast/model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = f's3://'+bucket+'/'+prefix_out\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "framework_version = '1.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-2-047892910832/paris-traffic-forecast/input'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_run = 60*60*6 # Max time in seconds\n",
    "\n",
    "estimator = PyTorch(entry_point = 'train_TFT.py',\n",
    "                                role = role,\n",
    "                                source_dir  = 'src',\n",
    "                                py_version = 'py38',\n",
    "                                max_run=max_run,\n",
    "                                framework_version = framework_version,\n",
    "                                instance_count = 1,\n",
    "                                instance_type='ml.p3.2xlarge', #'ml.m4.xlarge',#'ml.p2.xlarge',#'ml.p3.2xlarge',#\n",
    "                                output_path=f's3://'+bucket+'/'+prefix_out,\n",
    "                                hyperparameters={\n",
    "                                                    'train_fileName':'voi-convention2021.pkl',\n",
    "                                                    'pretrain_epochs':20,\n",
    "                                                    'finetune_epochs':10,\n",
    "\n",
    "                                }\n",
    "                               )\n",
    "input_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-12 04:10:32 Starting - Starting the training job...\n",
      "2021-12-12 04:11:01 Starting - Launching requested ML instancesProfilerReport-1639282232: InProgress\n",
      "...\n",
      "2021-12-12 04:11:25 Starting - Insufficient capacity error from EC2 while launching instances, retrying!...\n",
      "2021-12-12 04:12:03 Failed - Training job failed\n",
      "ProfilerReport-1639282232: Stopping\n",
      "."
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': input_channel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "trained_model_location = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "display('Model is here: {}'.format(trained_model_location))\n",
    "\n",
    "s3 = boto3.resource('s3')    \n",
    "s3.Bucket(bucket).download_file(prefix_out + '/' + desc['TrainingJobName'] + '/' + 'output/model.tar.gz','./models/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/model0'\n",
    "\n",
    "with tarfile.open('./models/model.tar.gz','r:gz') as archived:\n",
    "    archived.extractall(model_dir)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
